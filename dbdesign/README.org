#+title: Relational Database Design & Modeling

* Relational Language

A data model is a collection of conceptual tools for describing data, data relationships,
data semantics, and consistency constraints. The relational model uses a collection of
tables to represent both data and the relationships among those data. Its conceptual
simplicity has led to its widespread adoption; today a vast majority of database products
are based on the relational model. The relational model describes data at the logical and
view levels, abstracting away low-level details of data storage.

The relational model remains the primary data model for commercial data-processing
applications. It attained its primary position because of its simplicity, which eases the
job of the programmer, compared to earlier data models such as the network model or the
hierarchical model. It has retained this position by incorporating various new features and
capabilities over its half-century of existence. Among those additions are object-relational
features such as complex data types and stored procedures, support for XML data, and various
tools to support semi-structured data. The relational model’s independence from any speciﬁc
underlying low-level data structures has allowed it to persist despite the advent of new
approaches to data storage, including modern column- stores that are designed for
large-scale data mining.

A relational database consists of a collection of tables, each of which is assigned a unique
name. For example, consider the instructor the table, which stores information about
instructors. The table has four column headers: ID, name, dept name, and salary. Each row of
this table records information about an instructor, consisting of the instructor’s ID, name,
dept name, and salary. Similarly, the course stores information about
courses, consisting of a course id, title, dept name, and credits, for each course. Note
that each instructor is identiﬁed by the value of the column ID, while each course is
identiﬁed by the value of the column course id.

[[file:Relational_Language/2022-06-20_15-01-02_screenshot.png]]
[[file:Relational_Language/2022-06-20_14-55-43_screenshot.png]]

This shows another table, prereq, which stores the prerequisite courses for each course. The
table has two columns, course id and prereq id. Each row consists of a pair of course
identiﬁers such that the second course is a prerequisite for the ﬁrst course.

[[file:Relational_Language/2022-06-20_15-02-05_screenshot.png]]

Thus, a row in the prereq table indicates that two courses are related in the sense that one
course is a prerequisite for the other. As another example, when we consider the table
instructor, a row in the table can be thought of as representing the relationship.  between
a speciﬁed ID and the corresponding values for name, dept name, and salary values.


In general, a row in a table represents a relationship among a set of values. Since a table
is a collection of such relationships, there is a close correspondence between the concept
of table and the mathematical concept of relation, from which the relational data model
takes its name. In mathematical terminology, a _tuple_ is simply a sequence (or list) of
values. A relationship between n values is represented mathematically by an n-tuple of
values, that is, a tuple with n values, which corresponds to a row in a table.

Thus, in the relational model the term _relation_ is used to refer to a table, while the
term _tuple_ is used to refer to a row. Similarly, the term _attribute_ refers to a column
of a table.


For each attribute of a relation, there is a set of permitted values, called the _domain_ of
that attribute. Thus, the domain of the salary attribute of the instructor relation is the
set of all possible salary values, while the domain of the name attribute is the set of all
possible instructor names.


We require that, for all relations /r/, the domains of all attributes of /r/ be atomic.  A
domain is atomic if elements of the domain are considered to be indivisible units.  For
example, suppose the table instructor had an attribute phone number, which can store a set
of phone numbers corresponding to the instructor. Then the domain of phone number would not
be atomic, since an element of the domain is a set of phone numbers, and it has subparts,
namely, the individual phone numbers in the set.

** Note on Atomism
"Atomic" means "cannot be divided or split in smaller parts". Applied to 1NF this means that
a column should not contain more than one value. It should not compose or combine values
that have a meaning of their own.

This tipically regards 2 very common mistakes made by database designers:

*** 1. Multiple Values in One Column (list columns)
columns that contain a list of values, tipically space or comma separated, like this blog post table:
#+begin_src c
id title     date_posted content tags
1  new idea  2014-05-23  ...     tag1,tag2,tag3
2  why this? 2014-05-24  ...     tag2,tag5
3  towel day 2014-05-26  ...     tag42
#+end_src

or this contacts table:
#+begin_src c
id room phones
4  432  111-111-111 222-222-222
5  456  999-999-999
6  512  888-888-8888 333-3333-3333
#+end_src

This type of denormalization is rare, as most database designers see this cannot be a good
thing. But you do find tables like this. They usually come from modifications to the
database, whereas it may seem simpler to widen a column and use it to stuff multiple values
instead of adding a normalized related table (which often breaks existing applications).




*** 2. Complex Multi-Part Columns
In this case one column contains different bits of information and could maybe be designed
as a set of separate columns.

Typical example are fullname and address columns:

#+begin_src c
id fullname              address
1  Mark Tomers           56 Tomato Road
2  Fred Askalong         3277 Hadley Drive
3  May Anne Brice        225 Century Avenue - apartment 43/a
#+end_src


These types of denormalizations are very common, as it is quite difficult to draw the line
and what is atomic and what is not. Depending on the application, a multi-part column could
very well be the best solution in some cases. It is less structured, but simpler.

Structuring an address in many atomic columns may mean having more complex code to handle
results for output. Another complexity comes from the structure not being adeguate to fit
all types of addresses. Using one single VARCHAR column does not pose this problem, but may
pose others... typically about searching and sorting.

An extreme case of multi-part columns are dates and times. Most RDBMS provide date and time
data types and provide functions to handle date and time algebra and the extraction of the
various bits (month, hour, etc...). Few people would consider convenient to have separate
year, mont, day columns in a relational database. But I've seen it... and with good reasons:
the use case was birthdates for a justice department database. They had to handle many
immigrants with few or no documents. Sometimes you just knew a person was born in a certain
year, but you would not know the day or month or birth. You can't handle that type of info
with a single date column.


------

Let's get back to the phone numbers. The important issue is not what the domain itself is,
but rather how we use domain elements in our database. Suppose now that the phone number
attribute stores a single phone number. Even then, if we split the value from the phone
number attribute into a country code, an area code, and a local number, we would be treating
it as a non-atomic value. If we treat each phone number as a single indivisible unit, then
the attribute phone number would have an atomic domain.

The null value is a special value that signiﬁes that the value is unknown or does not exist.
For example, suppose as before that we include the attribute phone number in the instructor
relation. It may be that an instructor does not have a phone number at all, or that the
telephone number is unlisted. We would then have to use the null value to signify that the
value is unknown or does not exist. We shall see later that null values cause a number of
diﬃculties when we access or update the database, and thus they should be eliminated if at
all possible. We shall assume null values are absent initially.


The relatively strict structure of relations results in several important practical
advantages in the storage and processing of data, as we shall see. That strict structure is
suitable for well-deﬁned and relatively static applications, but it is less suitable for
applications where not only data but also the types and structure of those data change over
time. A modern enterprise needs to ﬁnd a good balance between the eﬃciencies of structured
data and those situations where a predetermined structure is limiting.

** Keys
We must have a way to specify how tuples within a given relation are distinguished.  This is
expressed in terms of their attributes. That is, the values of the attribute values of a
tuple must be such that they can uniquely identify the tuple. In other words, no two tuples
in a relation are allowed to have exactly the same value for all attributes.

A superkey is a set of one or more attributes that, taken collectively, allow us to identify
uniquely a tuple in the relation. For example, the ID attribute of the relation instructor
is suﬃcient to distinguish one instructor tuple from another. Thus, ID is a superkey. The
name attribute of instructor, on the other hand, is not a superkey, because several
instructors might have the same name


Formally, let /R/ denote the set of attributes in the schema of relation /r/. If we say that a
subset /K/ of /R/ is a superkey for /r/, we are restricting consideration to instances of
relations /r/ in which no two distinct tuples have the same values on all attributes in /K/.
That is, if /t1/ and /t2/ are in /r/ and /t1/ ≠ /t2/ , then /t1/./K/ ≠ /t2/.K.


A superkey may contain extraneous attributes. For example, the combination of ID and name is
a superkey for the relation instructor. If K is a superkey, then so is any superset of K. We
are often interested in superkeys for which no proper subset is a superkey. Such minimal
superkeys are called candidate keys.

It is possible that several distinct sets of attributes could serve as a candidate key.
Suppose that a combination of name and dept name is suﬃcient to distinguish among
members of the instructor relation. Then, both {ID} and {name, dept name} are candidate
keys. Although the attributes ID and name together can distinguish instructor tuples,
their combination, {ID, name}, does not form a candidate key, since the attribute ID
alone is a candidate key.


We shall use the term primary key to denote a candidate key that is chosen by the
database designer as the principal means of identifying tuples within a relation. A key
(whether primary, candidate, or super) is a property of the entire relation, rather than
of the individual tuples. Any two individual tuples in the relation are prohibited from
having the same value on the key attributes at the same time. The designation of a key
represents a constraint in the real-world enterprise being modeled. Thus, primary keys
are also referred to as primary key constraints.


** Basic Terminology Table:
| Term              | Relational Term                                                                                                                                            |
|-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Relation          | The term relation is used to refer to a table, while the term tuple is used to refer to a row. Similarly, the term attribute refers to a column of a table |
| Relation instance | We use the term relation instance to refer to a speciﬁc instance of a relation, that is, containing a speciﬁc set of rows                                  |
| Null value        | A placeholder to denote values that are missing or that we do not know                                                                                     |
| Database schema   | The logical design of the database                                                                                                                         |
| Relation schema   | The programming language notion of type deﬁnition.                                                                                                         |
| Superkey          | A superkey is a set of one or more attributes that, taken collectively, allow us to identify uniquely a tuple in the relation.                             |
| Canidate key      | A part of the superkey                                                                                                                                     |
|-------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------|


* Design
** Introduction
Nowadays, when people talk about a database, they usually refer to a Relational database,
but that has not always been the case. In fact, the term database is defined, by the Merriam
Webster English dictionary as, a "usually large collection of data organized especially for
rapid search and retrieval (as by a computer)". The Relational model is one way to organize
a large collection of data, but not the only one.

In the earlier days of computing, there was only one way to organize data. Due to the
limitations of storage on punch cards, punch tape, or magnetic tape, data had to stored as a
single continuous stream of data. This model for storing is data is called the /Sequential
file format/ or the /flat/ file format. A typical flat file would contain a series of
records, which corresponds to individual cards in a deck of punch card. Each record would
contain some information and in most cases, the information only made sense in the
sequential context of the file. For instance, the record with generic information about a
customer, could be followed by one or two address records, each containing an address. The
processing program would know which customer the address belongs to by reading the records
in order and remembering the last customer read.

The structure of flat flies could easily become quite complex. For instance, the customer
would not only have one or two addresses, they would hopefully, also place many orders and
each order could encompass multiple product ordered records. Records that track the product
ordered along with the quantity, the price, and the promise discount, if any. If the same
company then also wanted to trick their product catalog and automatically watch stock
levels, the second flat file would have to be added for the products. Each product would
have one record with generic product information, followed by number of records for
deliveries adding to our stock level, and then all the product ordered records for that
product. These records are the same collection of records also included in the customers
file, but in a different order, and the limitations of Sequential storage left, there's no
choice but to accept this duplication and try to write program code to prevent, but also
detect report, and repair any inconsistencies.

When spinning discs became available and affordable, new storage models were designed to
take advantage of the new ability to do Random IO with only a minor performance hit. The
first new kid on the block was the Hierarchal database. Conceptually, this was not very
different from the flat file model. The same data could still be processed in the same
order, but now that order was no longer implemented by storing the records in that specific
order, they could be stored anywhere on the disc. The logical order was imposed by so called
pointer chains. Each record would store a few extra bytes, the pointer, containing the
location on disc of the record that was logically next.

This new model only actually developed into a hierarchy because more than one pointer was
added to each record, but order record would not only have a pointer to its first product or
order record, but it would also have a pointer to the customer that placed the order and the
pointer to the next order record for the same customer allowing programs to process all
orders for a customer without having to read all the details of the order. Some
implementations would even add extra pointers to allow navigation in two directions, but
since storage was still very expensive in those days, not everyone was willing to pay for
those extra bytes.

The advantages of hierarchal databases were clear. The extra navigational possibilities
combined with the higher speed of spinning discs enabled businesses to create their first
programs to read, act upon, and modify data in real-time, but there were disadvantages as
well. The design of the database was very ridged. Modifications often required the database
to be dumped to a flat file, dropped, recreated, and then rebuilt from that flat file and
then all application programs also had to be modified to support a new design. Plus, data
such as the product orders records, still had to be stored multiple times if it was part of
multiple hierarchies.

The next development the Network database solved that. This database used the same pointer
technique as the Hierarchal database, but now even more pointers could be added to a record,
so that it could be a member of multiple hierarchies. So each product ordered record would
not only have pointers to their owning order in logically next product ordered record within
that hierarchy, but it would also have pointers to their owning product, the product being
ordered, and the logically next record within that hierarchy. This solved the problem of
having to duplicate data, but at the price of added complexity into the design of the
database, which of course was just as ridged as a hierarchal database.

In 1970, Dr. E. F.  Codd published a milestone scientific paper. He proposed a model for
data storage that abstracted all storage internals, such as pointers or physical storage
order, away from the users of the database. In his proposal, the model for data storage was
based on Mathematical Set Theory. This paper laid the foundation for the Storage Model that
is the most wide used now, the Relational Database. It took a lot of time before the
Relational database actually started to make an impact on the market mainly because the
requirements to storage capacity and processing power exceeded what was available in the
1970's, but once the hardware developments caught up, Relational technology took off to
become the defector standard for generic data storage.

** The Relational Model
The Relational Model is based on mathematics or to be more precise, on Set Theory and
First-order predicate logic. That doesn't mean you have to be a mathematician to use a
Relational database, but having some knowledge of these underlying concepts can help
understand some of the typical behavior of Relational databases. However, none of the
mainstream Relational databases are a true implementation of the Relational model. They all
feature details the deviate from the original Relational model.


In a Relational database, data is stored in one or more tables. Each table is a collection
of rows and columns, however, in Relational theory other terms are commonly used. A *table
is called a relation*, a *row is called a tuple*, and a *column is often called an
attribute.* Data values can be stored at every intersection of a row and a column. Both the
rows and the columns within each table are by definition in order. You cannot reference a
column as the third column, nor a row s the 21st row. Columns have to be referenced by their
name, which therefore has to be unique within each table and rows are referenced by one or
more of their attributes that combined uniquely identify a single row. The attributes that
are used for this purpose are called the *primary key*. This is one of the features that set
Relational databases off from all other storage methods available at that time. There are
still separate storage containers for separate kinds of data like customer order, and
product ordered, but the relationships between them like which order was placed by what
customer, are now no longer implemented in terms of physical storage. Instead, the
connection is made only on a logical basis by adding the primary key of a customer in the
storage area for an order.

A second important difference is that the rules for Relational databases only describe the
behavior of the database, not the implementation. So if in the records still choose to
implement the relationship by order and customer using a pointer, as long as this
implementation is handled transparently by the Relational engine, none are exposed to the
outside world. You don't even need to know anything about how a specific database implements
things and you would still be able to use it. Just as you don't need to know anything about
car engines in order to drive one, however, just as with car engines, having some knowledge
about the internals will help you to get more performance out of the engine.

Dr. Codd formulated a set of rules that are now known as Codd's Twelve Rules, even though
there are actually 13. There rules govern the behavior of Relational database management
systems. I will not cover them all, but I will explain some of them.

Rule 1, the Information Rule states that information can only be stored as values in a table
not in any other way. Rule 2, the Guaranteed Access Rule states that every value must be
accessible using a combination of a table name, a column name, and values of the primary key
columns.  Rule 3, Systematic Treatment of Null Values defines how missing data should be
handled. Data values can be stored at every intersection of a row and a column, but this
rule says that every such intersection can also store a special marker to indicate that
there is no data value at this intersection. This marker should be independent of the
columns data type, and it should be different from any value supported by the data type. So
no magic values suggest 0 or -1. The database management system should treat these markers
in a systematic way. Rule 5, the Comprehensive Data Sublanguage Rule states that the
database management system must support a language for data and schema manipulation that can
be used both programmatically and interactively. In all mainstream Relational database
management systems this language is SQL the Structured Query Language. Rule 7, High-level
Insert, Update, and Delete states that the language must provide the ability to insert,
update, or delete data in whole sets at a time. Rules 8 and 9, Physical Data Independence
and Logical Data Independence are related to shielding the application program from
implementation detials so that implementations choices can be changed without requiring a
change to the application code. Rule 10, Integrity Independence states that the database
management system must support the ability to define rules that govern data integrity as
part of the schema and that the database management system will then ensure that those rules
are not violated.

** Overview of the Design Process
The task of creating a database application is a complex one, involving design of the
database schema, design of the programs that access and update the data, and design of a
security scheme to control access to data. The needs of the users play a central role in the
design process.

*** Design Phases
For small applications, it may be feasible for a database designer who understands the
application requirements to decide directly on the relations to be created, their
attributes, and constraints on the relations. However, such a direct design process is
diﬃcult for real-world applications, since they are often highly complex. Often no one
person understands the complete data needs of an application. The database designer must
interact with users of the application to understand the needs of the application,
represent them in a high-level fashion that can be understood by the users, and then
translate the requirements into lower levels of the design. A high-level data model serves
the database designer by providing a conceptual framework in which to specify, in a
systematic fashion, the data requirements of the database users, and a database structure
that fulﬁlls these requirements.

The initial phase of database design is to characterize fully the data needs of the
prospective database users. The database designer needs to interact extensively with
domain experts and users to carry out this task. The outcome of this phase is a
speciﬁcation of user requirements.

Next, the designer chooses a data model and, by applying the concepts of the chosen data
model, translates these requirements into a conceptual schema of the database. The schema
developed at this conceptual-design phase provides a detailed overview of the enterprise.
The entity-relationship model, which we study in the rest of this chapter, is typically used
to represent the conceptual design. Stated in terms of the entity-relationship model, the
conceptual schema speciﬁes the entities that are represented in the database, the
attributes of the entities, the relation- ships among the entities, and constraints on the
entities and relationships. Typically, the conceptual-design phase results in the creation
of an entity-relationship diagram that provides a graphic representation of the schema.

A fully developed conceptual schema also indicates the functional requirements
of the enterprise. In a specification of functional requirements, users describe the
kinds of operations (or transactions) that will be performed on the data. Example
operations include modifying or updating data, searching for and retrieving spe-
ciﬁc data, and deleting data. At this stage of conceptual design, the designer can
review the schema to ensure that it meets functional requirements.

The process of moving from an abstract data model to the implementation of the database
proceeds in two ﬁnal design phases.

In the logical-design phase, the designer maps the high-level conceptual schema onto the
implementation data model of the database system that will be used.  The implementation data
model is typically the relational data model, and this step typically consists of mapping
the conceptual schema deﬁned using the entity-relationship model into a relation schema

The physical schema of a database can be changed relatively easily after an applica- tion
has been built. However, changes to the logical schema are usually harder to carry out,
since they may aﬀect a number of queries and updates scattered across application code. It
is therefore important to carry out the database design phase with care, before building the
rest of the database application.
*** The Entity-Relationship Model

The entity-relationship (E-R) data model was developed to facilitate database design by
allowing speciﬁcation of an enterprise schema that represents the overall logical struc-
ture of a database.

The E-R model is very useful in mapping the meanings and interactions of real- world
enterprises onto a conceptual schema. Because of this usefulness, many database- design
tools draw on concepts from the E-R model. The E-R data model employs three basic concepts:
entity sets, relationship sets, and attributes. The E-R model also has an associated
diagrammatic representation, the E-R diagram.

An entity is a “thing” or “object” in the real world that is distinguishable from all other
objects. For example, each person in a university is an entity. An entity has a set of prop-
erties, and the values for some set of properties must uniquely identify an entity. For
instance, a person may have a person id property whose value uniquely identiﬁes that person.

**** Entity Set
An entity is a “thing” or “object” in the real world that is distinguishable from all other
objects. For example, each person in a university is an entity. An entity has a set of prop-
erties, and the values for some set of properties must uniquely identify an entity. For
instance, a person may have a person id property whose value uniquely identiﬁes that
person. Thus, the value 677-89-9011 for person id would uniquely identify one particu-
lar person in the university. Similarly, courses can be thought of as entities, and course
id uniquely identiﬁes a course entity in the university. An entity may be concrete, such

An entity set is a set of entities of the same type that share the same properties,
or attributes. The set of all people who are instructors at a given university, for exam-
ple, can be deﬁned as the entity set instructor. Similarly, the entity set student might
represent the set of all students in the universit

An entity is represented by a set of attributes. Attributes are descriptive properties
possessed by each member of an entity set. The designation of an attribute for an en-
tity set expresses that the database stores similar information concerning each entity
in the entity set; however, each entity may have its own value for each attribute. Pos-
sible attributes of the instructor entity set are ID, name, dept name, and salary. In real
life, there would be further attributes, such as street number, apartment number, state,
postal code, and country, but we generally omit them to keep our examples simple.
Possible attributes of the course entity set are /course id, title, dept name, and credits/.


* TBC...
